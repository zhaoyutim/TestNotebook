{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()\n",
    "trainX = trainX.reshape(trainX.shape[0], 28, 28, 1).astype('float32')\n",
    "trainX = (trainX - 127.5) / 127.5\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Create a dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(trainX).shuffle(60000).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train (60000, 28, 28, 1) (60000,)\n",
      "Test (10000, 28, 28) (10000,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Train', trainX.shape, trainY.shape)\n",
    "print('Test', testX.shape, testY.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "def discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides=(2, 2), padding='same', input_shape=[28, 28, 1] ))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14a44b190>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "generator = generator()\n",
    "\n",
    "noise_input = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise_input, training = False)\n",
    "pyplot.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor([[0.00169876]], shape=(1, 1), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "discriminator = discriminator()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoints_dir = './training_checkpoints'\n",
    "checkpoints_prefix = os.path.join(checkpoints_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discrimitor_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator\n",
    "                                 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "EPOCHES = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 注意 `tf.function` 的使用\n",
    "# 该注解使函数被“编译”\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # 注意 training` 设定为 False\n",
    "  # 因此，所有层都在推理模式下运行（batchnorm）。\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = pyplot.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      pyplot.subplot(4, 4, i+1)\n",
    "      pyplot.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      pyplot.axis('off')\n",
    "\n",
    "  pyplot.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  pyplot.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import time \n",
    "from IPython import display\n",
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # 继续进行时为 GIF 生成图像\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # 每 15 个 epoch 保存一次模型\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoints_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # 最后一个 epoch 结束后生成图片\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3f14129b7e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a434e3e10828>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 继续进行时为 GIF 生成图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-13-d874c1f71976>:10 train_step  *\n        real_output = discriminator(images, training=True)\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__  **\n        self.name)\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [28, 28, 1]\n"
     ],
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-13-d874c1f71976>:10 train_step  *\n        real_output = discriminator(images, training=True)\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__  **\n        self.name)\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [28, 28, 1]\n",
     "output_type": "error"
    }
   ],
   "source": [
    "train(train_dataset, EPOCHES)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}